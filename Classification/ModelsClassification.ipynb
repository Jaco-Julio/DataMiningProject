{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('~/Classification/x_train.npy')\n",
    "X_test = np.load('~/Classification/x_test.npy')\n",
    "Y_test = np.load('~/Classification/Y_test.npy')\n",
    "Y_train = np.load('~/Classification/Y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the logistic regression algorithm and checking with the best parameter setting\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.970359 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.969579 (0.020370) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.560842 (0.170707) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.951638 (0.024230) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.969579 (0.020370) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.560842 (0.170707) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.952418 (0.025486) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.969579 (0.020370) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.560842 (0.170707) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.952418 (0.025486) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.968799 (0.023405) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.560842 (0.170707) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.952418 (0.025486) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.970359 (0.023842) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.560842 (0.170707) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.951638 (0.024258) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Showing the best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the KNN algorithm and checking with the best parameter setting\n",
    "model = KNeighborsClassifier()\n",
    "n_neighbors = range(1, 21, 2)\n",
    "weights = ['uniform', 'distance']\n",
    "metric = ['euclidean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.634945 using {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "0.618565 (0.072510) with: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.618565 (0.072510) with: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "0.623245 (0.063864) with: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.620125 (0.068068) with: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.606864 (0.065572) with: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.623245 (0.074998) with: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.600624 (0.073418) with: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.629485 (0.070529) with: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "0.591264 (0.079984) with: {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.625585 (0.074266) with: {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "0.605304 (0.089592) with: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "0.634945 (0.076615) with: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "0.600624 (0.093174) with: {'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "0.628705 (0.075094) with: {'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'distance'}\n",
      "0.594384 (0.086566) with: {'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'uniform'}\n",
      "0.628705 (0.074395) with: {'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "0.581903 (0.077998) with: {'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'uniform'}\n",
      "0.634165 (0.071505) with: {'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "0.592044 (0.077794) with: {'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'uniform'}\n",
      "0.634165 (0.072763) with: {'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Showing the best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the support vector machine algorithm and checking with the best parameter setting\n",
    "model = SVC()\n",
    "kernel = ['poly', 'rbf', 'sigmoid']\n",
    "C = [50, 10, 1.0, 0.1, 0.01]\n",
    "gamma = ['scale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = dict(kernel=kernel,C=C,gamma=gamma)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.538222 using {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.507540 (0.060487) with: {'C': 50, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.525221 (0.065794) with: {'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.470619 (0.070788) with: {'C': 50, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.507540 (0.060487) with: {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.538222 (0.063038) with: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.480499 (0.066870) with: {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.506500 (0.058664) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.509100 (0.041347) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.495060 (0.052621) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.513781 (0.065654) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.507020 (0.013722) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.510140 (0.003588) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.511700 (0.005974) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.510140 (0.003588) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.510140 (0.003588) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "# Showing the best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the Decision Tree with Bagging algorithm and checking with the best parameter setting\n",
    "model = BaggingClassifier()\n",
    "n_estimators = [10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = dict(n_estimators=n_estimators)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.972959 using {'n_estimators': 1000}\n",
      "0.966719 (0.018167) with: {'n_estimators': 10}\n",
      "0.971919 (0.019764) with: {'n_estimators': 100}\n",
      "0.972959 (0.021884) with: {'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Showing the best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the Random Forest algorithm and checking with the best parameter setting\n",
    "model = RandomForestClassifier()\n",
    "n_estimators = [10, 100, 1000]\n",
    "max_features = ['sqrt', 'log2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.981799 using {'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.977119 (0.016915) with: {'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.981279 (0.017678) with: {'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.980759 (0.017357) with: {'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.975039 (0.019884) with: {'max_features': 'log2', 'n_estimators': 10}\n",
      "0.979719 (0.015626) with: {'max_features': 'log2', 'n_estimators': 100}\n",
      "0.981799 (0.017542) with: {'max_features': 'log2', 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Showing the best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the XGBoost algorithm and checking with the best parameter setting\n",
    "model = GradientBoostingClassifier()\n",
    "n_estimators = [10, 100, 1000]\n",
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "subsample = [0.5, 0.7, 1.0]\n",
    "max_depth = [3, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.980759 using {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.510140 (0.003588) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.510140 (0.003588) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 10, 'subsample': 0.7}\n",
      "0.510140 (0.003588) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 10, 'subsample': 1.0}\n",
      "0.965679 (0.024761) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.964119 (0.023345) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n",
      "0.963079 (0.022460) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "0.969839 (0.022225) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "0.964639 (0.023295) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 0.7}\n",
      "0.962038 (0.022163) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 1.0}\n",
      "0.510140 (0.003588) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.510140 (0.003588) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 10, 'subsample': 0.7}\n",
      "0.510140 (0.003588) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 10, 'subsample': 1.0}\n",
      "0.973999 (0.021684) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.972439 (0.022199) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.7}\n",
      "0.957878 (0.026277) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 100, 'subsample': 1.0}\n",
      "0.974519 (0.020615) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "0.970879 (0.020645) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 1000, 'subsample': 0.7}\n",
      "0.956318 (0.025508) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 1000, 'subsample': 1.0}\n",
      "0.510140 (0.003588) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.510140 (0.003588) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 10, 'subsample': 0.7}\n",
      "0.510140 (0.003588) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 10, 'subsample': 1.0}\n",
      "0.974519 (0.020615) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.970359 (0.020513) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 100, 'subsample': 0.7}\n",
      "0.952158 (0.024600) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 100, 'subsample': 1.0}\n",
      "0.974519 (0.018996) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "0.968279 (0.021338) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 1000, 'subsample': 0.7}\n",
      "0.951118 (0.024155) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 1000, 'subsample': 1.0}\n",
      "0.964119 (0.028337) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.964119 (0.024026) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 10, 'subsample': 0.7}\n",
      "0.961518 (0.021438) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 10, 'subsample': 1.0}\n",
      "0.969839 (0.022225) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.964119 (0.022317) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n",
      "0.962038 (0.022163) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "0.977639 (0.018678) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "0.976599 (0.018655) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 0.7}\n",
      "0.973479 (0.019728) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 1.0}\n",
      "0.969839 (0.020432) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.968799 (0.020798) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 10, 'subsample': 0.7}\n",
      "0.956838 (0.027958) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 10, 'subsample': 1.0}\n",
      "0.975039 (0.018600) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.969839 (0.020367) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.7}\n",
      "0.956318 (0.026140) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'subsample': 1.0}\n",
      "0.979719 (0.018457) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "0.976599 (0.019112) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 1000, 'subsample': 0.7}\n",
      "0.966199 (0.020438) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 1000, 'subsample': 1.0}\n",
      "0.971919 (0.020604) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.967239 (0.023095) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 10, 'subsample': 0.7}\n",
      "0.952158 (0.023277) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 10, 'subsample': 1.0}\n",
      "0.974519 (0.019432) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.967759 (0.020720) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 100, 'subsample': 0.7}\n",
      "0.950598 (0.025599) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 100, 'subsample': 1.0}\n",
      "0.979719 (0.018457) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "0.977119 (0.017800) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 1000, 'subsample': 0.7}\n",
      "0.951118 (0.024179) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 1000, 'subsample': 1.0}\n",
      "0.967759 (0.024969) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.964639 (0.024600) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 10, 'subsample': 0.7}\n",
      "0.961518 (0.021814) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 10, 'subsample': 1.0}\n",
      "0.976599 (0.018245) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.976079 (0.018662) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n",
      "0.975039 (0.018220) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "0.976599 (0.016920) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "0.977119 (0.017799) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 0.7}\n",
      "0.977119 (0.019134) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 1.0}\n",
      "0.968799 (0.022930) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.969319 (0.020945) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 10, 'subsample': 0.7}\n",
      "0.958398 (0.024117) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 10, 'subsample': 1.0}\n",
      "0.980759 (0.016406) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.977119 (0.018261) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.7}\n",
      "0.964119 (0.022331) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'subsample': 1.0}\n",
      "0.979199 (0.018556) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "0.976599 (0.018252) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 1000, 'subsample': 0.7}\n",
      "0.966199 (0.021224) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 1000, 'subsample': 1.0}\n",
      "0.965159 (0.023504) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.966719 (0.023207) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 10, 'subsample': 0.7}\n",
      "0.949558 (0.024418) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 10, 'subsample': 1.0}\n",
      "0.979719 (0.018457) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.974519 (0.020590) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100, 'subsample': 0.7}\n",
      "0.952678 (0.025495) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100, 'subsample': 1.0}\n",
      "0.979199 (0.015754) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "0.975559 (0.019063) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 1000, 'subsample': 0.7}\n",
      "0.950598 (0.026579) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 1000, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Showing the best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the best classifiers with the best parameter settings\n",
    "Classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(C=0.01, penalty='l2', solver='newton-cg'),\n",
    "    'Bagging Classifier': BaggingClassifier(n_estimators=1000),\n",
    "    'Random Forest': RandomForestClassifier(max_features='sqrt', n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classifier:  Logistic Regression \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       144\n",
      "           1       0.98      0.94      0.96       131\n",
      "\n",
      "    accuracy                           0.96       275\n",
      "   macro avg       0.96      0.96      0.96       275\n",
      "weighted avg       0.96      0.96      0.96       275\n",
      "\n",
      "\n",
      " Confusion Matrix:  Logistic Regression \n",
      " [[141   3]\n",
      " [  8 123]]\n",
      "\n",
      " ROC Score:  Logistic Regression \n",
      " 0.959048982188295\n",
      "\n",
      " Classifier:  Bagging Classifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       144\n",
      "           1       0.95      0.96      0.96       131\n",
      "\n",
      "    accuracy                           0.96       275\n",
      "   macro avg       0.96      0.96      0.96       275\n",
      "weighted avg       0.96      0.96      0.96       275\n",
      "\n",
      "\n",
      " Confusion Matrix:  Bagging Classifier \n",
      " [[138   6]\n",
      " [  5 126]]\n",
      "\n",
      " ROC Score:  Bagging Classifier \n",
      " 0.9600826972010179\n",
      "\n",
      " Classifier:  Random Forest \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       144\n",
      "           1       0.96      0.98      0.97       131\n",
      "\n",
      "    accuracy                           0.97       275\n",
      "   macro avg       0.97      0.97      0.97       275\n",
      "weighted avg       0.97      0.97      0.97       275\n",
      "\n",
      "\n",
      " Confusion Matrix:  Random Forest \n",
      " [[139   5]\n",
      " [  3 128]]\n",
      "\n",
      " ROC Score:  Random Forest \n",
      " 0.9711885072094996\n",
      "\n",
      " Classifier:  Gradient Boosting \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       144\n",
      "           1       0.96      0.99      0.97       131\n",
      "\n",
      "    accuracy                           0.97       275\n",
      "   macro avg       0.97      0.98      0.97       275\n",
      "weighted avg       0.98      0.97      0.97       275\n",
      "\n",
      "\n",
      " Confusion Matrix:  Gradient Boosting \n",
      " [[138   6]\n",
      " [  1 130]]\n",
      "\n",
      " ROC Score:  Gradient Boosting \n",
      " 0.975349872773537\n"
     ]
    }
   ],
   "source": [
    "# Showing the main metrics\n",
    "for key, classifier in Classifiers.items():\n",
    "    classifier_fitted = classifier.fit(X_train, Y_train)\n",
    "    y_pred = classifier_fitted.predict(X_test)\n",
    "    print('\\n Classifier: ', key,'\\n', classification_report(Y_test, y_pred))\n",
    "    print('\\n Confusion Matrix: ', key,'\\n', confusion_matrix(Y_test, y_pred))\n",
    "    print('\\n ROC Score: ', key, '\\n', roc_auc_score(Y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
